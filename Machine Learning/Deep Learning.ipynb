{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1930264-94a5-423e-8976-b5736644b3fb",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Setting up the ML Problem](#1)\n",
    "    - [1.1 - Train/Dev/Test Sets](#1-1)\n",
    "    - [1.2 - Bias/Variance](#1-2)\n",
    "    - [1.3 - Normalizing Inputs](#1-3)\n",
    "    - [1.4 - Initialisation of Weights](#1-4)\n",
    "    - [1.5 - Activation Functions](#1-5)\n",
    "    - [1.6 - Optimisation Algorithms](#1-6)\n",
    "    - [1.7 - Batch Normalisation](#1-7)\n",
    "- [2 - ML Strategy](#2)\n",
    "    - [2.1 - Setting up your Goal](#2-1)\n",
    "    - [2.2 - Error Analysis](#2-2)\n",
    "    - [2.3 - Transfer Learning](#2-3)\n",
    "- [3 - Convolutional Neural Networks (CNN)](#3)\n",
    "    - [3.1 - Intro to CNN](#3-1)\n",
    "    - [3.2 - CNN Networks](#3-2)\n",
    "        - [3.2.1 - Classic Networks](#3-2-1)\n",
    "        - [3.2.2 - ResNets](#3-2-2)\n",
    "        - [3.2.3 - Inception Network](#3-2-3)\n",
    "        - [3.2.4 - Mobile Net](#3-2-4)\n",
    "    - [3.3 - Object Detection](#3.3)\n",
    "        - [3.3.1 - YOLO (You Only Look Once)](#3-3-1)\n",
    "        - [3.3.2 - Image Segmentation: U-Net](#3-3-2)\n",
    "        - [3.3.3 - Face Recognition (FaceNet)](#3-3-3)\n",
    "        - [3.3.4 - Neural Style Transfer](#3-3-4)\n",
    "- [4 - Sequential Models - RNN](#4)\n",
    "    - [4.1 - Intro to RNN](#4-1)\n",
    "    - [4.2 - Word Embeddings](#4-2)\n",
    "        - [4.2.1 - Word2Vec](#4-2-1)\n",
    "        - [4.2.2 - Negative Sampling](#4-2-2)\n",
    "        - [4.2.3 - GloVe Word Vectors](#4-2-3)\n",
    "    - [4.3 - Sequence to Sequence Models](#4-3)\n",
    "        - [4.3.1 - Conditional Language Models](#4-3-1)\n",
    "    - [4.4 - Attention Models](#4-4)\n",
    "        - [4.4.1 - Self Attention](#4-4-1)\n",
    "        - [4.4.2 - Multi-Head Attention](#4-4-2)\n",
    "        - [4.4.3 - Transformers](#4-4-3)\n",
    "- [5 - Tensorflow](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f2c02-6813-4e06-87d2-28fb5ae03706",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# 1 - Setting up the ML Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f8b3f-3dc0-457e-8d9b-1e6302a66b54",
   "metadata": {},
   "source": [
    "<a name='1-1'></a>\n",
    "## 1.1 - Train/Dev/Test Sets\n",
    "- Train set data can be of any distribution, does not need to be of same distribution as dev/test set\n",
    "- **Dev set should have same data distribution as the test set, and should be representative of actual use case data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f4659-69b8-4f1a-a337-3fa23d37f73b",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "## 1.2 - Bias/Variance\n",
    "**High Bias:** large difference in Bayes error and train set error **(Underfitting)**\n",
    "- Train a bigger neural network\n",
    "- Train longer\n",
    "- Adjust neural network architecture\n",
    "\n",
    "**High Variance:** large difference in train set and validation set error **(Overfitting)**\n",
    "- Use more data for training\n",
    "- Regularization\n",
    "    - L1/L2 Regularization\n",
    "        - L1 Loss produces a sparse weights result, can be used for feature selection\n",
    "        - L2 Loss is more commonly used\n",
    "     - Dropout:\n",
    "         - Intuition: Forces the neural network to be unable to rely on any one feature/node, so have to spread out weights.\n",
    "     - Data Augmentation\n",
    "         - Increases amount of training data and reduces overfitting\n",
    "     - Weight Decay\n",
    "     - Early Stopping\n",
    "         - Issue: Affects two areas simultaneously, it optimizes the cost function and regularises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6782d8-5767-4c75-a119-e5ee92e173f5",
   "metadata": {},
   "source": [
    "<a name='1-3'></a>\n",
    "## 1.3 - Normalizing Inputs\n",
    "- Helps to **speed up training** as it affects the rate of learning in gradient descent, due to the descent direction being more directed toward the minimum\n",
    "    - Ensures a more symmetrical descent direction, instead of an elongated bowl cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee046f7-6bc8-4e9f-b1e7-a8c786263fda",
   "metadata": {},
   "source": [
    "<a name='1-4'></a>\n",
    "## 1.4 - Initialisation of Weights\n",
    "- The weights $W^{[l]}$ should be **initialized randomly to break symmetry**\n",
    "- **Do not initialize weights to be too large**, else the learning rate will be very slow\n",
    "    - When using Relu/Sigmoid activation functions, the gradient at very large/very small values is close to 0, hence learning rate becomes very slow\n",
    "    - Prevents vanishing/exploding gradients\n",
    "    - Recommended Initialization Methods:\n",
    "        - **Xavier Initialization**: Scaling factor of `sqrt(1./layers_dims[l-1])`\n",
    "        - **He Initialization**: Scaling factor of `sqrt(2./layers_dims[l-1])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847573aa-951c-4acf-923b-3df028cbb927",
   "metadata": {},
   "source": [
    "<a name='1-5'></a>\n",
    "## 1.5 - Activation Functions\n",
    "- `sigmoid`: range from 0 to 1, use for binary classification output layer\n",
    "- `tanh`: range from -1 to +1, almost always better than the sigmoid function due to mean 0 (data is centered)\n",
    "- `Relu`: `max(0, z)` **recommended**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d957056-aa29-450b-86c4-a17084b04c04",
   "metadata": {},
   "source": [
    "<a name='1-6'></a>\n",
    "## 1.6 - Optimisation Algorithms\n",
    "- Gradient Descent with Momentum\n",
    "- RMSprop\n",
    "- **Adam**: combines both the concepts of using momentum as well as RMSprop\n",
    "    - $\\alpha$: need to tune\n",
    "    - $\\beta_1$: 0.9 $\\rightarrow$ $dW$\n",
    "    - $\\beta_2$: 0.999 $\\rightarrow$ $dW^2$\n",
    "    - $\\epsilon$: $10^{-8}$\n",
    "- Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27827efc-d1ec-4896-afd8-8b6dc09a94c8",
   "metadata": {},
   "source": [
    "<a name='1-7'></a>\n",
    "## 1.7 - Batch Normalisation\n",
    "Normalizes all the output activations $a^l$ to train $w^{l+1}$ and $b^{l+1}$ faster, and helps with **internal covariate shift**\n",
    "\n",
    "Implementation:\n",
    " - Given some intermediate values in layer L of NN: $z^{(1)}, \\dots, z^{(m)}$\n",
    " - $\\mu = \\frac{1}{m}\\sum_i z^{(i)}$\n",
    " - $\\sigma^2 = \\frac{1}{m}\\sum_i (z^{(i)} - \\mu)^2$\n",
    " - $z^{(i)}_{norm} = \\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}$\n",
    " - $\\tilde{z}^{(i)} = \\gamma z^{(i)}_{norm} + \\beta$\n",
    " \n",
    "Last step is because you may not want all your hidden unit values to have mean 0 and variance 1 (e.g. having a sigmoid function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccdffc0-e80d-461c-a4a5-40287a506f50",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# 2 - ML Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0ed9b-d801-4fe7-b9ad-874ea8889bf8",
   "metadata": {},
   "source": [
    "<a name='2-1'></a>\n",
    "## 2.1 - Setting up your Goal\n",
    "- Single Number Evaluation Metric\n",
    "    - Makes it easier to compare different algorithms performance across different datasets\n",
    "- Satisficing and Optimizing Metrics\n",
    "- Train/Dev/Test Distributions\n",
    "    - Choose a dev and test set to reflect data expected to get in the future and consider important to perform well on\n",
    "    - Set dev set size to be big enough to detect differences in models being tried out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b754af-6565-4f26-aed9-28adcacaf88b",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "## 2.2 - Error Analysis\n",
    "**Quickly build a first model, then analyse the errors it is making and iterate on it**\n",
    "\n",
    "Manually look at a subset of the incorrectly labelled examples in the validation/dev set. Label each example with the appropriate reason for mismatch.\n",
    "\n",
    "Provides a way to quickly approximate what errors to focus on, provides a benchmark for the \"maximum\" improvement to the model if a certain error is fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f9825-bff9-4bd3-b528-3e8ee11c5a22",
   "metadata": {},
   "source": [
    "<a name='2-3'></a>\n",
    "## 2.3 - Transfer Learning\n",
    "**Transfer learning from A $\\rightarrow$ B**\n",
    "\n",
    "**Reasons for Use:**\n",
    "- Task A and B have the same input $x$\n",
    "- Have a lot more data for Task A than Task B\n",
    "- Low level features from A could be helpful for learning B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ec713-15ad-4287-9496-f9f025e2d5d0",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "# 3 - Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a58ed9-0097-408c-a1e6-3370a5dd3571",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "## 3.1 - Intro to CNN\n",
    "**Reasons for CNN**\n",
    "- **Parameter sharing**: A feature detector that is useful in one part of the image is probably useful in another part of the image\n",
    "- **Sparsity of Connections**: In each layer, each output layer depends only on a small number of inputs\n",
    "\n",
    "**Padding**: Extra zeros added to the border of image\n",
    "- Valid: Any convolution where output size is **not equal** to the input size\n",
    "- Same: Pad the input so that the output size is the **same** as the input size\n",
    "**Strides**\n",
    "- The number of units to move when taking the next filter\n",
    "    \n",
    "If layer $l$ is a convolutional layer:\n",
    "- $f^{[l]} = \\text{filter size}$\n",
    "- $p^{[l]} = \\text{padding }$\n",
    "- $s^{[l]} = \\text{stride}$\n",
    "- $n_C = \\text{number of filters (channels)}$\n",
    "- $\\text{Input} = n_H^{[l-1]} * n_W^{[l-1]} * n_C^{[l-1]}$\n",
    "- $\\text{Output} = n_H^{[l]} * n_W^{[l]} * n_C^{[l]}$\n",
    "\n",
    "$$n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f^{[l]} + 2 * p^{[l]}}{s^{[l]}} \\Bigr\\rfloor +1$$\n",
    "$$n_W = n_H$$\n",
    "    \n",
    "**Types of Layers**\n",
    "- Convolutional (CONV)\n",
    "- Pooling (POOL)\n",
    "- Fully Connected (FC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a81fc6-3572-4486-a2f1-cdaa6bbe6916",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "## 3.2 - CNN Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d7ebce-4376-4608-b662-308c063ebd72",
   "metadata": {},
   "source": [
    "<a name='3-2-1'></a>\n",
    "### 3.2.1 - Classic Networks\n",
    "- LeNet-5\n",
    "- AlexNet\n",
    "- VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c50165-62df-4e91-9773-c49cf7b15a05",
   "metadata": {},
   "source": [
    "<a name='3-2-2'></a>\n",
    "### 3.2.2 - ResNets (Residual Networks)\n",
    "ResNets have skip connections/\"shortcuts\" that pass the output from $a^{[l]}$ to the input for $a^{[l+2]}$\n",
    "\n",
    "<font color = 'blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "\n",
    "- Very deep \"plain\" networks don't work in practice because vanishing gradients make them hard to train.  \n",
    "- Skip connections **help address the Vanishing Gradient problem**. They also make it easy for a ResNet block to learn an identity function. \n",
    "- There are two main types of blocks: The **identity block** and the **convolutional block**. \n",
    "- Very deep Residual Networks are built by stacking these blocks together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403bd17-4251-44fb-9981-61b3d5dc6a9c",
   "metadata": {},
   "source": [
    "<a name='3-2-3'></a>\n",
    "### 3.2.3 - Inception Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eba71a-9a6d-4e90-967a-95bacf0ee3e7",
   "metadata": {},
   "source": [
    "<a name='3-2-4'></a>\n",
    "### 3.2.4 - MobileNets\n",
    "Designed to provide fast and computationally efficient performance by using **depthwise separable convolutions**\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "    \n",
    "* MobileNetV2's unique features are: \n",
    "  * Depthwise separable convolutions that provide lightweight feature filtering and creation\n",
    "  * Input and output bottlenecks that preserve important information on either end of the block\n",
    "* Depthwise separable convolutions deal with both spatial and depth (number of channels) dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ade09d-e616-4aff-92a2-7f719e6195a1",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "## 3.3 - Object Detection\n",
    "\n",
    "**Non-Max Suppression**: ensures that only one bounding box is drawn per object\n",
    "- Discard all boxes with $p_c \\leq probability$\n",
    "- While there are any remaining boxes\n",
    "    - Pick the box with the highest $p_c$ and output as prediction\n",
    "    - Discard any remaining box with IoU (Intersection over Union) $\\geq probability$ with the box output in the previous step\n",
    "    \n",
    "**Anchor boxes**: define anchor boxes for the shapes of objects to be detected, to address issues of overlapping objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23666840-3213-4398-9eac-9224c955b9d6",
   "metadata": {},
   "source": [
    "<a name='3-3-1'></a>\n",
    "### 3.3.1 - YOLO (You Only Look Once) Algorithm\n",
    "\n",
    "Fast object detection model that draws bounding boxes around the objects\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "    \n",
    "- YOLO is a state-of-the-art object detection model that is fast and accurate\n",
    "- It runs an input image through a CNN, which outputs a 19x19x5x85 dimensional volume. \n",
    "- The encoding can be seen as a grid where each of the 19x19 cells contains information about 5 boxes.\n",
    "- You filter through all the boxes using non-max suppression. Specifically: \n",
    "    - Score thresholding on the probability of detecting a class to keep only accurate (high probability) boxes\n",
    "    - Intersection over Union (IoU) thresholding to eliminate overlapping boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0976e11e-b80b-4634-bf0d-f62293fa225c",
   "metadata": {},
   "source": [
    "<a name='3-3-2'></a>\n",
    "### 3.3.2 - Image Segmentation: U-Net\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "\n",
    "* **Semantic image segmentation predicts a label for every single pixel in an image**\n",
    "* U-Net uses an equal number of convolutional blocks and transposed convolutions for downsampling and upsampling\n",
    "* **Skip connections** are used to prevent border pixel information loss and overfitting in U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa32d3c-e5a2-4f3c-ad13-cc597b0b3d3e",
   "metadata": {},
   "source": [
    "<a name='3-3-3'></a>\n",
    "### 3.3.3 - Face Recognition (Face Net)\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "    \n",
    "- Face verification solves an easier 1:1 matching problem; face recognition addresses a harder 1:K matching problem.\n",
    "- Triplet loss is an effective loss function for training a neural network to learn an encoding of a face image.\n",
    "- The same encoding can be used for verification and recognition. Measuring distances between two images' encodings allows you to determine whether they are pictures of the same person.\n",
    "- Face recognition is a one-shot learning problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34b58b-81b2-4b71-9fb5-a921ac8fcaf8",
   "metadata": {},
   "source": [
    "<a name='3-3-4'></a>\n",
    "### 3.3.4 - Neural Style Transfer\n",
    "\n",
    "<font color = 'blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "    \n",
    "- The style of an image can be represented using the Gram matrix of a hidden layer's activations. \n",
    "- You get even better results by combining this representation from multiple different layers. \n",
    "- This is in contrast to the content representation, where usually using just a single hidden layer is sufficient.\n",
    "- Minimizing the style cost will cause the image $G$ to follow the style of the image $S$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af22823-7068-4f47-abb9-e02ad8d54ad3",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "# 4 - Sequential Models - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eae2e2-6b5d-4ebd-95f6-c345fba25bb2",
   "metadata": {},
   "source": [
    "<a name='4-1'></a>\n",
    "## 4.1 - Intro to RNN\n",
    "\n",
    "<font color = 'blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "    \n",
    "- The recurrent neural network, or RNN, is essentially the repeated use of a single cell.\n",
    "- A basic RNN reads inputs one at a time, and remembers information through the hidden layer activations (hidden states) that are passed from one time step to the next.\n",
    "    - The time step dimension determines how many times to re-use the RNN cell\n",
    "- Each cell takes two inputs at each time step:\n",
    "    - The hidden state from the previous cell\n",
    "    - The current time step's input data\n",
    "- Each cell has two outputs at each time step:\n",
    "    - A hidden state \n",
    "    - A prediction\n",
    "    \n",
    "## LSTM\n",
    "\n",
    "<b>What you should remember</b>:\n",
    " \n",
    "- An LSTM is similar to an RNN in that they both use hidden states to pass along information, but an LSTM also uses a cell state, which is like a long-term memory, to help deal with the issue of vanishing gradients\n",
    "- An LSTM cell consists of a cell state (long-term memory), a hidden state (short-term memory), along with 3 gates that constantly update the relevancy of its inputs:\n",
    "    - A <b>forget</b> gate, which decides which input units should be remembered and passed along. It's a tensor with values between 0 and 1. \n",
    "        - If a unit has a value close to 0, the LSTM will \"forget\" the stored state in the previous cell state.\n",
    "        - If it has a value close to 1, the LSTM will mostly remember the corresponding value.\n",
    "    - An <b>update</b> gate, again a tensor containing values between 0 and 1. It decides on what information to throw away, and what new information to add.\n",
    "        - When a unit in the update gate is close to 1, the value of its candidate is passed on to the hidden state.\n",
    "        - When a unit in the update gate is close to 0, it's prevented from being passed onto the hidden state.\n",
    "    - And an <b>output</b> gate, which decides what gets sent as the output of the time step\n",
    "\n",
    "## GRU\n",
    "- Has less gates than LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8c117-e95e-44ac-a342-40e1530af805",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "## 4.2 - Word Embeddings\n",
    "Creates vectors to represent the \"meaning\" of each word, with words of similar meaning being closer together\n",
    "\n",
    "Can learn word embeddings from large text corpus (1 - 100B words). **Useful for transfer learning.**\n",
    "\n",
    "<font color = 'blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "    \n",
    "- If you have an NLP task where the **training set is small**, using word embeddings can help your algorithm significantly. \n",
    "- **Word embeddings allow your model to work on words in the test set that may not even appear in the training set.**\n",
    "- Training sequence models in Keras (and in most other deep learning frameworks) requires a few important details:\n",
    "    - To use mini-batches, the sequences need to be **padded** so that all the examples in a mini-batch have the **same length**. \n",
    "    - An `Embedding()` layer can be initialized with pretrained values. \n",
    "        - These values can be either fixed or trained further on your dataset. \n",
    "        - If however your labeled dataset is small, it's usually not worth trying to train a large pre-trained set of embeddings.   \n",
    "    - `LSTM()` has a flag called `return_sequences` to decide if you would like to return every hidden states or only the last one. \n",
    "    - You can use `Dropout()` right after `LSTM()` to regularize your network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52375cf3-a27a-4355-b9e3-d3a0a09b6a7e",
   "metadata": {},
   "source": [
    "<a name='4-2-1'></a>\n",
    "### 4.2.1 - Word2Vec\n",
    "Trained using **Skip-grams**\n",
    "\n",
    "Issues: Softmax is slow to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db5927-08f9-4579-b1ad-8d234a30c0c0",
   "metadata": {},
   "source": [
    "<a name='4-2-2'></a>\n",
    "### 4.2.2 - Negative Sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437652c7-aae5-4e48-91a7-6290a77846eb",
   "metadata": {},
   "source": [
    "<a name='4-2-3'></a>\n",
    "### 4.2.3 - GloVe Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f682f-f35d-4cea-8468-8e0dcc87591c",
   "metadata": {},
   "source": [
    "<a name='4-3'></a>\n",
    "## 4.3 - Sequence to Sequence Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0134c-7929-4949-aa44-b508b72a98ca",
   "metadata": {},
   "source": [
    "<a name='4-3-1'></a>\n",
    "### 4.3.1 - Conditional Language Models\n",
    "Picks the next word, based on the highest conditional probability of all the previous words selected.\n",
    "\n",
    "**Beam Search** is used instead of greedy search, as beam search enables a wider search range, allowing for more diverse sentences to be constructed. Beam search stores the top $n$ sentences at every iteration, and loops on each to find the next best $n$ sentences. **Runs fast but not guaranteed to find exact maximum for argmax**.\n",
    "\n",
    "**Error Analysis for Beam Search**: If conditional probability of correct sentence $P(y^*|x) >$ conditional probability of outputted sentence $P(\\hat{y}|x)$, then **RNN is working correctly and beam search range $n$ should be increased**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940610b-d49b-424c-a509-3ddac714d716",
   "metadata": {},
   "source": [
    "<a name='4-4'></a>\n",
    "## 4.4 - Attention Models\n",
    "\n",
    "Solves the issue of long sequences by paying attention to the relevant parts in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5477a3-6993-4668-b2b6-41f8dd006d0a",
   "metadata": {},
   "source": [
    "<a name='4-4-1'></a>\n",
    "## 4.4.1 - Self-Attention\n",
    "$A(q, K, V)$ = attention-based vector representation of a word\n",
    "$$\n",
    "Attention(Q, K, V) = softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "- Query ($Q$) \n",
    "- Key ($K$)\n",
    "- Value ($V$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034d841-af5a-422d-82da-b89d97429c71",
   "metadata": {},
   "source": [
    "<a name='4-4-2'></a>\n",
    "## 4.4.2 - Multi-Head Attention\n",
    "Stacks of Self-Attention in order to answer multiple questions\n",
    "\n",
    "<font color='blue'>\n",
    "    <b>What you should remember</b>:\n",
    "\n",
    "- The combination of self-attention and convolutional network layers allows of parallization of training and *faster training*.\n",
    "- Self-attention is calculated using the generated query Q, key K, and value V matrices.\n",
    "- Adding positional encoding to word embeddings is an effective way of include sequence information in self-attention calculations. \n",
    "- Multi-head attention can help detect multiple features in your sentence.\n",
    "- Masking stops the model from 'looking ahead' during training, or weighting zeroes too much when processing cropped sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3677e4a-d077-48d2-a005-b7da47bfa066",
   "metadata": {},
   "source": [
    "<a name='4-4-3'></a>\n",
    "## 4.4.3 - Transformer\n",
    "When traning a Transformer network, all the data is fed into the model at once. This dramatically reduces training time but loses the information of ordering of the data, hence we use positional encoding - to specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:\n",
    "$$\n",
    "PE_{(pos, 2i)}= sin\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n",
    "\\tag{1}$$\n",
    "<br>\n",
    "$$\n",
    "PE_{(pos, 2i+1)}= cos\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n",
    "\\tag{2}$$\n",
    "\n",
    "* $d$ is the dimension of the word embedding and positional encoding\n",
    "* $pos$ is the position of the word.\n",
    "* $i$ refers to each of the different dimensions of the positional encoding.\n",
    "\n",
    "Satisfies the following criteria:\n",
    "- It should output a unique encoding for each time-step (wordâ€™s position in a sentence)\n",
    "- Distance between any two time-steps should be consistent across sentences with different lengths.\n",
    "- Our model should generalize to longer sentences without any efforts. Its values should be bounded.\n",
    "- It must be deterministic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903c516-8501-4f9e-b5f8-10369b3d5888",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "# 5 - Tensorflow\n",
    "## Streaming the Data\n",
    "\n",
    "Here you should take note of an important extra step that's been added to the batch training process: \n",
    "\n",
    "- `tf.Data.dataset = dataset.prefetch(8)` \n",
    "\n",
    "What this does is prevent a memory bottleneck that can occur when reading from disk. `prefetch()` sets aside some data and keeps it ready for when it's needed. It does this by creating a source dataset from your input data, applying a transformation to preprocess the data, then iterating over the dataset the specified number of elements at a time. This works because the iteration is streaming, so the data doesn't need to fit into the memory. \n",
    "\n",
    "`X_train = X_train.batch(minibatch_size, drop_remainder=True).prefetch(8)` # <<< extra step    \n",
    "`Y_train = Y_train.batch(minibatch_size, drop_remainder=True).prefetch(8)` # loads memory faster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b6a53-5eb7-4e2a-99c2-ef60ce82a3e9",
   "metadata": {},
   "source": [
    "You may have encountered `dataset.prefetch` in a previous TensorFlow assignment, as an important extra step in data preprocessing. \n",
    "\n",
    "Using `prefetch()` prevents a memory bottleneck that can occur when reading from disk. It sets aside some data and keeps it ready for when it's needed, by creating a source dataset from your input data, applying a transformation to preprocess it, then iterating over the dataset one element at a time. Because the iteration is streaming, the data doesn't need to fit into memory.\n",
    "\n",
    "You can set the number of elements to prefetch manually, or you can use `tf.data.experimental.AUTOTUNE` to choose the parameters automatically. Autotune prompts `tf.data` to tune that value dynamically at runtime, by tracking the time spent in each operation and feeding those times into an optimization algorithm. The optimization algorithm tries to find the best allocation of its CPU budget across all tunable operations. \n",
    "\n",
    "To increase diversity in the training set and help your model learn the data better, it's standard practice to augment the images by transforming them, i.e., randomly flipping and rotating them. Keras' Sequential API offers a straightforward method for these kinds of data augmentations, with built-in, customizable preprocessing layers. These layers are saved with the rest of your model and can be re-used later.  Ahh, so convenient! \n",
    "\n",
    "As always, you're invited to read the official docs, which you can find for data augmentation [here](https://www.tensorflow.org/tutorials/images/data_augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e8369-eb07-4860-b70e-2ad56fbc82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
